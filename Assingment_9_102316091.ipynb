{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**ASSINGMENT 9 CC **\n",
        "\n"
      ],
      "metadata": {
        "id": "6A72vzashoBx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1\n",
        "Write a unique paragraph (5-6 sentences) about your favorite topic (e.g., sports, technology, food, books, etc.).\n",
        "\n",
        "1. Convert text to lowercase and remove punctuaƟon.\n",
        "2. Tokenize the text into words and sentences.\n",
        "3. Remove stopwords (using NLTK's stopwords list).\n",
        "4. Display word frequency distribuƟon (excluding stopwords)"
      ],
      "metadata": {
        "id": "5UarJTIgiIAB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pgcx7xc-hmNu",
        "outputId": "b84c64ec-c5c7-4006-bfc0-22e48e2fdd46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Text:\n",
            "\n",
            "in a quiet village nestled between hills a young boy named arin discovered an old robot buried beneath the soil \n",
            "curious and brave he repaired it piece by piece learning about circuits and code along the way \n",
            "one day the robot blinked to life and from that moment arin and his metallic friend began fixing broken tools helping farmers and bringing light to homes \n",
            "the village soon called him “the boy who woke the machine” and his story became a legend of friendship between human and technology\n",
            "\n",
            "\n",
            "Tokens:\n",
            "['in', 'a', 'quiet', 'village', 'nestled', 'between', 'hills', 'a', 'young', 'boy', 'named', 'arin', 'discovered', 'an', 'old', 'robot', 'buried', 'beneath', 'the', 'soil', 'curious', 'and', 'brave', 'he', 'repaired', 'it', 'piece', 'by', 'piece', 'learning', 'about', 'circuits', 'and', 'code', 'along', 'the', 'way', 'one', 'day', 'the', 'robot', 'blinked', 'to', 'life', 'and', 'from', 'that', 'moment', 'arin', 'and', 'his', 'metallic', 'friend', 'began', 'fixing', 'broken', 'tools', 'helping', 'farmers', 'and', 'bringing', 'light', 'to', 'homes', 'the', 'village', 'soon', 'called', 'him', '“', 'the', 'boy', 'who', 'woke', 'the', 'machine', '”', 'and', 'his', 'story', 'became', 'a', 'legend', 'of', 'friendship', 'between', 'human', 'and', 'technology']\n",
            "\n",
            "Filtered Words:\n",
            "['quiet', 'village', 'nestled', 'hills', 'young', 'boy', 'named', 'arin', 'discovered', 'old', 'robot', 'buried', 'beneath', 'soil', 'curious', 'brave', 'repaired', 'piece', 'piece', 'learning', 'circuits', 'code', 'along', 'way', 'one', 'day', 'robot', 'blinked', 'life', 'moment', 'arin', 'metallic', 'friend', 'began', 'fixing', 'broken', 'tools', 'helping', 'farmers', 'bringing', 'light', 'homes', 'village', 'soon', 'called', '“', 'boy', 'woke', 'machine', '”', 'story', 'became', 'legend', 'friendship', 'human', 'technology']\n",
            "Word Frequency Distribution (Excluding Stopwords):\n",
            "Counter({'village': 2, 'boy': 2, 'arin': 2, 'robot': 2, 'piece': 2, 'quiet': 1, 'nestled': 1, 'hills': 1, 'young': 1, 'named': 1, 'discovered': 1, 'old': 1, 'buried': 1, 'beneath': 1, 'soil': 1, 'curious': 1, 'brave': 1, 'repaired': 1, 'learning': 1, 'circuits': 1, 'code': 1, 'along': 1, 'way': 1, 'one': 1, 'day': 1, 'blinked': 1, 'life': 1, 'moment': 1, 'metallic': 1, 'friend': 1, 'began': 1, 'fixing': 1, 'broken': 1, 'tools': 1, 'helping': 1, 'farmers': 1, 'bringing': 1, 'light': 1, 'homes': 1, 'soon': 1, 'called': 1, '“': 1, 'woke': 1, 'machine': 1, '”': 1, 'story': 1, 'became': 1, 'legend': 1, 'friendship': 1, 'human': 1, 'technology': 1})\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.stem import PorterStemmer, LancasterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from collections import Counter\n",
        "\n",
        "# NLTK resources\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Sample text\n",
        "text = \"\"\"\n",
        "In a quiet village nestled between hills, a young boy named Arin discovered an old robot buried beneath the soil.\n",
        "Curious and brave, he repaired it piece by piece, learning about circuits and code along the way.\n",
        "One day, the robot blinked to life, and from that moment, Arin and his metallic friend began fixing broken tools, helping farmers, and bringing light to homes.\n",
        "The village soon called him “The Boy Who Woke the Machine,” and his story became a legend of friendship between human and technology.\n",
        "\"\"\"\n",
        "\n",
        "# 1. Convert text to lowercase and remove punctuation\n",
        "text_lower = text.lower()\n",
        "text_clean = text_lower.translate(str.maketrans('', '', string.punctuation))\n",
        "print(\"Cleaned Text:\")\n",
        "print(text_clean)\n",
        "\n",
        "# 2. Tokenize the text into words and sentence\n",
        "words = word_tokenize(text_clean)\n",
        "sentences = sent_tokenize(text)\n",
        "print(\"\\nTokens:\")\n",
        "print(words)\n",
        "\n",
        "# 3. Remove stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_words = [word for word in words if word not in stop_words]\n",
        "print(\"\\nFiltered Words:\")\n",
        "print(filtered_words)\n",
        "\n",
        "# 4. Display word frequency distribution\n",
        "word_freq = Counter(filtered_words)\n",
        "print(\"Word Frequency Distribution (Excluding Stopwords):\")\n",
        "print(word_freq)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2.Stemming and LemmaƟzaƟon\n",
        "1. Take the tokenized words from QuesƟon 1 (aŌer stopword removal).\n",
        "2. Apply stemming using NLTK's PorterStemmer and LancasterStemmer.\n",
        "3. Apply lemmaƟzaƟon using NLTK's WordNetLemmaƟzer.\n",
        "4. Compare and display results of both techniques."
      ],
      "metadata": {
        "id": "zd7YEm9ykBnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize stemmers and lemmatizer\n",
        "porter_stemmer = PorterStemmer()\n",
        "lancaster_stemmer = LancasterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Apply stemming using PorterStemmer and LancasterStemmer\n",
        "porter_stemmed = [porter_stemmer.stem(word) for word in filtered_words]\n",
        "lancaster_stemmed = [lancaster_stemmer.stem(word) for word in filtered_words]\n",
        "\n",
        "# Apply lemmatization using WordNetLemmatizer\n",
        "lemmatized = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
        "\n",
        "# Compare and display results of both techniques\n",
        "print(\"\\nStemming (PorterStemmer):\", porter_stemmed)\n",
        "print(\"\\nStemming (LancasterStemmer):\", lancaster_stemmed)\n",
        "print(\"\\nLemmatization:\", lemmatized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRHMaKwMhp5z",
        "outputId": "3c2a936a-d60b-4465-8769-1c78002fb477"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Stemming (PorterStemmer): ['quiet', 'villag', 'nestl', 'hill', 'young', 'boy', 'name', 'arin', 'discov', 'old', 'robot', 'buri', 'beneath', 'soil', 'curiou', 'brave', 'repair', 'piec', 'piec', 'learn', 'circuit', 'code', 'along', 'way', 'one', 'day', 'robot', 'blink', 'life', 'moment', 'arin', 'metal', 'friend', 'began', 'fix', 'broken', 'tool', 'help', 'farmer', 'bring', 'light', 'home', 'villag', 'soon', 'call', '“', 'boy', 'woke', 'machin', '”', 'stori', 'becam', 'legend', 'friendship', 'human', 'technolog']\n",
            "\n",
            "Stemming (LancasterStemmer): ['quiet', 'vil', 'nestl', 'hil', 'young', 'boy', 'nam', 'arin', 'discov', 'old', 'robot', 'bury', 'benea', 'soil', 'cury', 'brav', 'repair', 'piec', 'piec', 'learn', 'circuit', 'cod', 'along', 'way', 'on', 'day', 'robot', 'blink', 'lif', 'mom', 'arin', 'metal', 'friend', 'beg', 'fix', 'brok', 'tool', 'help', 'farm', 'bring', 'light', 'hom', 'vil', 'soon', 'cal', '“', 'boy', 'wok', 'machin', '”', 'story', 'becam', 'legend', 'friend', 'hum', 'technolog']\n",
            "\n",
            "Lemmatization: ['quiet', 'village', 'nestled', 'hill', 'young', 'boy', 'named', 'arin', 'discovered', 'old', 'robot', 'buried', 'beneath', 'soil', 'curious', 'brave', 'repaired', 'piece', 'piece', 'learning', 'circuit', 'code', 'along', 'way', 'one', 'day', 'robot', 'blinked', 'life', 'moment', 'arin', 'metallic', 'friend', 'began', 'fixing', 'broken', 'tool', 'helping', 'farmer', 'bringing', 'light', 'home', 'village', 'soon', 'called', '“', 'boy', 'woke', 'machine', '”', 'story', 'became', 'legend', 'friendship', 'human', 'technology']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. Regular Expressions and Text Spliƫng\n",
        "\n",
        "1. Take their original text from QuesƟon 1.\n",
        "2. Use regular expressions to: a. Extract all words with more than 5 leƩers. b. 2.Extract all numbers (if any exist in their text). c. Extract all capitalized words.\n",
        "3. Use text spliƫng techniques to: a. Split the text into words containing only alphabets (removing digits and special characters). b. Extract words starƟng with a vowel."
      ],
      "metadata": {
        "id": "XX9Nh0UKk0UQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Use regular expressions to extract:\n",
        "# a. All words with more than 5 letters\n",
        "long_words = re.findall(r'\\b\\w{6,}\\b', text_clean)\n",
        "print(\"\\nWords with more than 5 letters:\", long_words)\n",
        "\n",
        "# b. All numbers\n",
        "numbers = re.findall(r'\\b\\d+\\b', text_clean)\n",
        "print(\"\\nNumbers found in text:\", numbers)\n",
        "\n",
        "# c. All capitalized words\n",
        "capitalized_words = re.findall(r'\\b[A-Z][a-z]*\\b', text_clean)\n",
        "print(\"\\nCapitalized words:\", capitalized_words)\n",
        "\n",
        "# 2. Use text splitting techniques:\n",
        "# a. Split the text into words containing only alphabets\n",
        "alphabetic_words = re.findall(r'\\b[a-zA-Z]+\\b', text_clean)\n",
        "print(\"\\nAlphabetic words:\", alphabetic_words)\n",
        "\n",
        "# b. Extract words starting with a vowel\n",
        "vowel_words = re.findall(r'\\b[aeiouAEIOU]\\w*\\b', text_clean)\n",
        "print(\"\\nWords starting with a vowel:\", vowel_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oml59FJkSOX",
        "outputId": "3fa5f124-d867-48d3-d9ff-c8fbd0b142f6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Words with more than 5 letters: ['village', 'nestled', 'between', 'discovered', 'buried', 'beneath', 'curious', 'repaired', 'learning', 'circuits', 'blinked', 'moment', 'metallic', 'friend', 'fixing', 'broken', 'helping', 'farmers', 'bringing', 'village', 'called', 'machine', 'became', 'legend', 'friendship', 'between', 'technology']\n",
            "\n",
            "Numbers found in text: []\n",
            "\n",
            "Capitalized words: []\n",
            "\n",
            "Alphabetic words: ['in', 'a', 'quiet', 'village', 'nestled', 'between', 'hills', 'a', 'young', 'boy', 'named', 'arin', 'discovered', 'an', 'old', 'robot', 'buried', 'beneath', 'the', 'soil', 'curious', 'and', 'brave', 'he', 'repaired', 'it', 'piece', 'by', 'piece', 'learning', 'about', 'circuits', 'and', 'code', 'along', 'the', 'way', 'one', 'day', 'the', 'robot', 'blinked', 'to', 'life', 'and', 'from', 'that', 'moment', 'arin', 'and', 'his', 'metallic', 'friend', 'began', 'fixing', 'broken', 'tools', 'helping', 'farmers', 'and', 'bringing', 'light', 'to', 'homes', 'the', 'village', 'soon', 'called', 'him', 'the', 'boy', 'who', 'woke', 'the', 'machine', 'and', 'his', 'story', 'became', 'a', 'legend', 'of', 'friendship', 'between', 'human', 'and', 'technology']\n",
            "\n",
            "Words starting with a vowel: ['in', 'a', 'a', 'arin', 'an', 'old', 'and', 'it', 'about', 'and', 'along', 'one', 'and', 'arin', 'and', 'and', 'and', 'a', 'of', 'and']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4 . Custom TokenizaƟon & Regex-based Text Cleaning\n",
        "\n",
        "1. Take original text from QuesƟon 1.\n",
        "2. Write a custom tokenizaƟon funcƟon that: a. Removes punctuaƟon and special symbols, but keeps contracƟons (e.g., \"isn't\" should not be split into \"is\" and \"n't\"). b. Handles hyphenated words as a single token (e.g., \"state-of-the-art\" remains a single token). c. Tokenizes numbers separately but keeps decimal numbers intact (e.g., \"3.14\" should remain as is).\n",
        "3. Use Regex SubsƟtuƟons (re.sub) to: a. Replace email addresses with '' placeholder. b. Replace URLs with '' placeholder. c. Replace phone numbers (formats: 123-456-7890 or +91 9876543210) with '' placeholder."
      ],
      "metadata": {
        "id": "rq29HkAnlj4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Custom tokenization function\n",
        "def custom_tokenizer(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s\\'-]', '', text)\n",
        "    return word_tokenize(text)\n",
        "\n",
        "custom_tokens = custom_tokenizer(text)\n",
        "print(\"\\nCustom Tokenized Text:\", custom_tokens)\n",
        "\n",
        "# 2. Regex substitutions for cleaning\n",
        "# a. Replace email addresses with '<EMAIL>'\n",
        "text_with_emails = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,7}\\b', '<EMAIL>', text)\n",
        "# b. Replace URLs with '<URL>'\n",
        "text_with_urls = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '<URL>', text_with_emails)\n",
        "# c. Replace phone numbers with '<PHONE>'\n",
        "text_cleaned = re.sub(r'(\\+?\\d{1,2}\\s?)?(\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4})', '<PHONE>', text_with_urls)\n",
        "\n",
        "print(\"\\nText with Emails, URLs, and Phone Numbers Replaced:\")\n",
        "print(text_cleaned)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvVz9xe3lHfr",
        "outputId": "15322f28-2e2a-4945-b4c3-697eeb711d39"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Custom Tokenized Text: ['in', 'a', 'quiet', 'village', 'nestled', 'between', 'hills', 'a', 'young', 'boy', 'named', 'arin', 'discovered', 'an', 'old', 'robot', 'buried', 'beneath', 'the', 'soil', 'curious', 'and', 'brave', 'he', 'repaired', 'it', 'piece', 'by', 'piece', 'learning', 'about', 'circuits', 'and', 'code', 'along', 'the', 'way', 'one', 'day', 'the', 'robot', 'blinked', 'to', 'life', 'and', 'from', 'that', 'moment', 'arin', 'and', 'his', 'metallic', 'friend', 'began', 'fixing', 'broken', 'tools', 'helping', 'farmers', 'and', 'bringing', 'light', 'to', 'homes', 'the', 'village', 'soon', 'called', 'him', 'the', 'boy', 'who', 'woke', 'the', 'machine', 'and', 'his', 'story', 'became', 'a', 'legend', 'of', 'friendship', 'between', 'human', 'and', 'technology']\n",
            "\n",
            "Text with Emails, URLs, and Phone Numbers Replaced:\n",
            "\n",
            "In a quiet village nestled between hills, a young boy named Arin discovered an old robot buried beneath the soil. \n",
            "Curious and brave, he repaired it piece by piece, learning about circuits and code along the way. \n",
            "One day, the robot blinked to life, and from that moment, Arin and his metallic friend began fixing broken tools, helping farmers, and bringing light to homes. \n",
            "The village soon called him “The Boy Who Woke the Machine,” and his story became a legend of friendship between human and technology.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "juiP7eMMlyvn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}